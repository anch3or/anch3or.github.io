<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>seq2seq_with_attention</title>
    <link href="/2020/05/03/seq2seq-with-attention/"/>
    <url>/2020/05/03/seq2seq-with-attention/</url>
    
    <content type="html"><![CDATA[<h1 id="Seq2Seq-with-Attention"><a href="#Seq2Seq-with-Attention" class="headerlink" title="Seq2Seq with Attention"></a>Seq2Seq with Attention</h1><script type="math/tex; mode=display">\begin{align}\end{align}</script><h2 id="1-序列到序列任务中的注意力机制"><a href="#1-序列到序列任务中的注意力机制" class="headerlink" title="1 序列到序列任务中的注意力机制"></a>1 序列到序列任务中的注意力机制</h2><h3 id="Seq2Seq-with-Attention网络架构"><a href="#Seq2Seq-with-Attention网络架构" class="headerlink" title="Seq2Seq with Attention网络架构"></a>Seq2Seq with Attention网络架构</h3><p><img src="https://i.loli.net/2020/05/03/tjJTB8Mbq3ngLW2.png" srcset="/img/loading.gif"  align=center  width = "300" height = "400" /></p><p>seq2seq with Attention神经网络架构中，编码器采用双向循环神经网络学习将输入序列$\mathbf{x}$编码成每个时刻的上下文向量（注意力分布）$c_i$，解码器学习将上下文向量$c_i$解码为输出序列$\mathbf{y}$。</p><p>源文本序列：$\mathbf{x}=\left(x_1,\cdots,x_{T_x}\right)$，其中$x_i\in\mathbb{R}^{K_x}$为one-of-K编码 ，$K_x$为源语言词表长度，$T_x$为源语料长度。<br>目标文本序列：$\mathbf{y}=\left(y_1,\cdots,y_{T_y}\right)$，其中$y_i\in\mathbb{R}^{K_y}$为one-of-K编码，$K_y$为目标语言词表长度，$T_y$为目标语料长度。</p><h3 id="Seq2Seq-with-Attention编码器Encoder原理"><a href="#Seq2Seq-with-Attention编码器Encoder原理" class="headerlink" title="Seq2Seq with Attention编码器Encoder原理"></a>Seq2Seq with Attention编码器Encoder原理</h3><p>编码器Encoder采用双向循环神经网络，前向状态计算</p><script type="math/tex; mode=display">\overrightarrow{h}_i=\left\{\begin{aligned}& \left(1-\overrightarrow{z}_i\right)\circ\overrightarrow{h}_{i-1}+\overrightarrow{z}_i\circ\overrightarrow{\underline{h}}_i& ,\mathbf{i}\mathbf{f}\ i>0\\& 0 &, \mathbf{i}\mathbf{f}\ i=0\end{aligned}\right.</script><p>其中，</p><script type="math/tex; mode=display">\overrightarrow{\underline{h}}_i=\tanh\left(\overrightarrow{W}\overline{E}x_i+\overrightarrow{U}\left[\overrightarrow{r}_i\circ\overrightarrow{h}_{i-1}\right]\right)  \\\overrightarrow{z}_i=\sigma\left(\overrightarrow{W}_z\overline{E}x_i+\overrightarrow{U}_z\overrightarrow{h}_{i-1}\right) \\\overrightarrow{r}_i=\sigma\left(\overrightarrow{W}_r\overline{E}x_i+\overrightarrow{U}_r\overrightarrow{h}_{i-1}\right)</script><p>$\overline{E}\in\mathbb{R}^{m\times K_x}$为词嵌入矩阵，$m$为词嵌入维度。$\overrightarrow{W},\overrightarrow{W}_z,\overrightarrow{W}_r\in\mathbb{R}^{n\times m}$和$\overrightarrow{U},\overrightarrow{U}_z,\overrightarrow{U}_r\in\mathbb{R}^{n\times n}$为权值矩阵，$n$为隐藏单元数。$\sigma\left(\cdot\right)$通常为sigmoid函数。</p><p>后向状态$\left(\overleftarrow{h}_1,\cdots,\overleftarrow{h}_{T_x}\right)$计算相同。与权值矩阵不同，我们在前向和后向RNN网络中共享词嵌入矩阵$\overline{E}$。</p><p>将前向和后向状态关联起来得到注释$\left(h_1,h_2,\cdots,h_{T_x}\right)$，<br>其中，<script type="math/tex">h_i=\begin{bmatrix}\overrightarrow{h}_i\\\overleftarrow{h}_i\end{bmatrix}</script></p><h3 id="Seq2Seq-with-Attention解码器Decoder原理"><a href="#Seq2Seq-with-Attention解码器Decoder原理" class="headerlink" title="Seq2Seq with Attention解码器Decoder原理"></a>Seq2Seq with Attention解码器Decoder原理</h3><p>解码器Decoder隐层转态$s_i$由解码器注释$h_i$计算的注意力分布$c_i$得到</p><script type="math/tex; mode=display">s_i=\left(1-z_i\right)\circ s_{i-1}+z_i\circ\tilde{s}_i</script><p>其中，</p><script type="math/tex; mode=display">\tilde{s}_i=\tanh\left(WEy_{i-1}+U\left[r_i\circ s_{i-1}\right]+Cc_i\right) \\z_i=\sigma\left(W_zEy_{i-1}+U_zs_{i-1}+C_rc_i\right) \\r_i=\sigma\left(W_rEy_{i-1}+U_rs_{i-1}+C_rc_i\right)</script><p>$E\in\mathbb{R}^{m\times K_y}$为目标语言的词嵌入矩阵，$m$为词嵌入维度。$W,W_z,W_r\in\mathbb{R}^{n\times m}$和$U,U_z,U_r\in\mathbb{R}^{n\times n}$以及<br>$C,C_z,C_r\in\mathbb{R}^{n\times 2n}$为权值矩阵，$n$为隐藏单元数。隐层初始状态$s_0=\tanh\left(W_s\overleftarrow{h}_1\right)$，其中$W_s\in\mathbb{R}^{n\times n}$。</p><p>每个时刻的上下文向量（注意力分布）$c_i$的计算</p><script type="math/tex; mode=display">c_i=\sum_{j=1}^{T_x}a_{ij}h_j</script><p>其中，</p><script type="math/tex; mode=display">a_{ij}=\frac{\exp\left(e_{ij}\right)}{\sum_{k=1}^{T_x}\exp\left(e_{ik}\right)}    \\ e_{ij}=v_a^\top\tanh\left(W_as_{i-1}+U_ah_j\right)</script><p>$h_j$为源文本序列第$j$个注释。$v_a\in\mathbb{R}^{n^{‘}},W_a\in\mathbb{R}^{n^{‘}\times n},U_a\in\mathbb{R}^{n^{‘}\times 2n}$为权值矩阵。</p><p>使用解码器状态$s_{i-1}$，上下文$c_i$和上时刻生成单词$y_{i-1}$定义目标单词$y_i$的概率</p><script type="math/tex; mode=display">p\left(y_i|s_i,y_{i-1},c_i\right)\propto\exp\left(y_i^\top W_o t_i\right)</script><p>其中，</p><script type="math/tex; mode=display">t_i=\left[\max\left\{\tilde{t}_{i,2j-1},\tilde{t}_{i,wj}\right\}\right]_{j=1,\cdots,l}^\top</script><p>$\tilde{t}_{i,k}$是向量$\tilde{t}_i$的第$k$个元素，</p><script type="math/tex; mode=display">\tilde{t}_i=U_os_{i-1}+V_oEy_{i-1}+C_oc_i</script><p>$W_o\in\mathbb{R}^{K_y\times l},U_o\in\mathbb{R}^{2l\times n},C_o\in\mathbb{R}^{2l\times 2n}$是权值矩阵。</p><h2 id="2-注意力机制"><a href="#2-注意力机制" class="headerlink" title="2 注意力机制"></a>2 注意力机制</h2><h3 id="柔性注意力机制（Soft-Attention）"><a href="#柔性注意力机制（Soft-Attention）" class="headerlink" title="柔性注意力机制（Soft Attention）"></a>柔性注意力机制（Soft Attention）</h3><p>输入信息$X=\left[\mathbf{x}_1,\cdots,\mathbf{x}_N\right]$</p><p>注意力机制的计算：</p><ol><li>在输入信息上计计算注意力分布；</li><li>根据注意力分布计算输入信息的加权平均。</li></ol><h4 id="注意力分布"><a href="#注意力分布" class="headerlink" title="注意力分布"></a>注意力分布</h4><p>给定一个和任务相关的查询向量$\mathbf{q}$，用注意力变量$z\in\left[1,N\right]$表示被选择信息的索引位置，即$z=i$表示选择了第$i$个输入信息。其中，查询向量$\mathbf{q}$可以是动态生成的，也可以是可学习的参数。</p><p>软性注意力的注意力分布<br>在给定输入信息$X$和查询变量$\mathbf{q}$下，选择第$i$个输入信息的概率</p><script type="math/tex; mode=display">\begin{align}\alpha_i&=p\left(z=i|X,\mathbf{q}\right) \\&=softmax\left(s\left(\mathbf{x}_i,\mathbf{q}\right)\right) \\&=\frac{\exp\left(s\left(\mathbf{x}_i,\mathbf{q}\right)\right)}{\sum_{j=1}^N\exp\left(s\left(\mathbf{x}_j,\mathbf{q}\right)\right)}\end{align}</script><p>其中，$\alpha_i$称为注意力分布，$s\left(\mathbf{x}_i,\mathbf{q}\right)$称为注意力打分函数。</p><p>注意力打分函数</p><ul><li>加性模型  $s\left(\mathbf{x}_i,\mathbf{q}\right)=\mathbf{v}^\top\tanh\left(W\mathbf{x}_i+U\mathbf{q}\right)$</li><li>点积模型  $s\left(\mathbf{x}_i,\mathbf{q}\right)=\mathbf{x}_i^\top\mathbf{q}$</li><li>缩放点积模型 $s\left(\mathbf{x}_i,\mathbf{q}\right)=\frac{\mathbf{x}_i^\top\mathbf{q}}{\sqrt{d}}$</li><li>双线性模型 $s\left(\mathbf{x}_i,\mathbf{q}\right)=\mathbf{x}_i^\top W\mathbf{q}$  </li></ul><p>其中，$W,U,\mathbf{v}$为可学习的网络参数，$d$为输入信息的维度。<br>加性模型和点积模型的复杂度近似，但点积模型可利用矩阵乘积，计算效率跟高。当输入信息的维度$d$比较高，点积模型值方差较大，导致softmax函数的梯度较小，缩放点积模型可以解决。双线性模型是泛化的点积模型。若假设$W=U^\top V$，则$s\left(\mathbf{x}_i,\mathbf{q}\right)=\mathbf{x}_i^\top U^\top V\mathbf{q}=\left(U\mathbf{x}_i\right)^\top\left(V\mathbf{q}\right)$，即分别对$\mathbf{x}_i$和$\mathbf{q}$进行线性变换后进行点积。相比点积模型，双线性模型在计算相似度是引入了非对称性。</p><p>注意力分布$\alpha_i$可解释为在给定相关查询$\mathbf{q}$时，第$i$个信息受关注的程度。</p><h4 id="加权平均"><a href="#加权平均" class="headerlink" title="加权平均"></a>加权平均</h4><p>注意力函数</p><script type="math/tex; mode=display">\begin{align}att\left(X,\mathbf{q}\right)&=\sum_{i=1}^N\alpha_i\mathbf{x}_i  \\&=\mathbb{E}_{z\thicksim p\left(z|X,\mathbf{q}\right)}\left[\mathbf{x}\right]\end{align}</script><p><img src="https://i.loli.net/2020/05/03/sHoKExjqJeTpgF6.png" srcset="/img/loading.gif"  align=center  width = "300" height = "300" /></p><h3 id="键值对注意力机制（Key-Value-Pair-Attention-Mechanism）"><a href="#键值对注意力机制（Key-Value-Pair-Attention-Mechanism）" class="headerlink" title="键值对注意力机制（Key-Value Pair Attention Mechanism）"></a>键值对注意力机制（Key-Value Pair Attention Mechanism）</h3><p>输入信息$\left(K,V\right)=\left[\left(\mathbf{k}_1,\mathbf{v}_1\right),\cdots,\left(\mathbf{k}_N,\mathbf{v}_N\right)\right]$，其中键用来计算注意力分布$\alpha_i$，值用来计算聚合信息。</p><p>给定任务相关查询向量$\mathbf{q}$时，注意力分布</p><script type="math/tex; mode=display">\alpha_i=\frac{\exp\left(s\left(\mathbf{k}_i,\mathbf{q}\right)\right)}{\sum_{j=1}^N\exp\left(s\left(\mathbf{k}_j,\mathbf{q}\right)\right)}</script><p>注意力函数</p><script type="math/tex; mode=display">\begin{align}att\left(\left(K,V\right),\mathbf{q}\right)&=\sum_{i=1}^N\alpha_i\mathbf{v}_i \\&=\sum_{i=1}^N\frac{\exp\left(s\left(\mathbf{k}_i,\mathbf{q}\right)\right)}{\sum_{j=1}^N\exp\left(s\left(\mathbf{k}_j,\mathbf{q}\right)\right)}\mathbf{v}_i\end{align}</script><p>其中，$s\left(\mathbf{k}_i,\mathbf{q}\right)$为打分函数。当$K=V$时，键值对注意力机制等价为柔性注意力机制。</p><p><img src="https://i.loli.net/2020/05/03/BJSWRXqLU1milEK.png" srcset="/img/loading.gif"  align=center  width = "300" height = "300" /></p><h3 id="多头注意力机制（Multi-Head-Attention-Mechanism）"><a href="#多头注意力机制（Multi-Head-Attention-Mechanism）" class="headerlink" title="多头注意力机制（Multi-Head Attention Mechanism）"></a>多头注意力机制（Multi-Head Attention Mechanism）</h3><p>多个查询$Q=\left[\mathbf{q}_1,\cdots,\mathbf{q}_M\right]$平行的计算从输入信息中选取多个信息。每个注意力关注输入信息的不同部分。</p><script type="math/tex; mode=display">att\left(\left(K,V\right),Q\right)=att\left(\left(K,V\right),\mathbf{q}_1\right)\oplus\cdots\oplus att\left(\left(K,V\right),\mathbf{q}_M\right)</script><p>其中，$\oplus$为向量拼接。</p><h3 id="自注意力模型（Self-Attention-Model）"><a href="#自注意力模型（Self-Attention-Model）" class="headerlink" title="自注意力模型（Self-Attention Model）"></a>自注意力模型（Self-Attention Model）</h3><p>输入序列$X=\left[\mathbf{x}_1,\cdots,\mathbf{x}_N\right]\in\mathbb{R}^{d_1\times N}$<br>输出序列$H=\left[\mathbf{h}_1,\cdots,\mathbf{h}_N\right]\in\mathbb{R}^{d_2\times N}$</p><p>通过线性变换得到向量序列：</p><script type="math/tex; mode=display">Q=W_QX\in\mathbb{R}^{d_3\times N}     \\K=W_KX\in\mathbb{R}^{d_3\times N}       \\V=W_VX\in\mathbb{R}^{d_2\times N}</script><p>其中，$Q$为查询向量序列，$K$为键向量序列，$V$为值向量序列，$W_Q,W_K,W_V$分别为可学习参数矩阵。</p><p>预测输出向量</p><script type="math/tex; mode=display">\begin{align}\hat{\mathbf{h}}_i&=att\left(\left(K,V\right),\mathbf{q}_i\right) \\&=\sum_{j=1}^N\alpha_{ij}\mathbf{v}_j \\&=\sum_{j=1}^Nsoftmax\left(s\left(\mathbf{k}_j,\mathbf{q}_i\right)\right)\mathbf{v}_j\end{align}</script><p>其中，$i,j\in\left[1,N\right]$为输出和输入向量序列的位置，连接权重$\alpha_{ij}$由注意力机制动态生成。</p><p>若使用缩放点积模型作为打分函数，则输出向量序列</p><script type="math/tex; mode=display">\begin{align}H_{d_2\times N}&=softmax\left(\frac{K^\top Q}{\sqrt{d_3}}\right)V_{d_2\times N} \\&=softmax\left(\frac{K^\top Q}{\sqrt{d_3}}\right)W_VX\end{align}</script><p>其中，softmax为按列归一化的函数。</p><p>自注意力模型计算的权重$\alpha_{ij}$只依赖$\mathbf{q}_i$和$\mathbf{k}_j$的相关性，而忽略了输入信息的位置信息。因此自注意力模型一般需要加入位置编码信息来进行修正。</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>multi-head attention</tag>
      
      <tag>nlp</tag>
      
      <tag>seq2seq</tag>
      
      <tag>attention</tag>
      
      <tag>soft attention</tag>
      
      <tag>key-value pair attention</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>seq2seq_with_Encoder-Decoder</title>
    <link href="/2020/05/03/seq2seq-with-Encoder-Decoder/"/>
    <url>/2020/05/03/seq2seq-with-Encoder-Decoder/</url>
    
    <content type="html"><![CDATA[<h1 id="seq2seq-with-Encoder-Decoder"><a href="#seq2seq-with-Encoder-Decoder" class="headerlink" title="seq2seq with Encoder-Decoder"></a>seq2seq with Encoder-Decoder</h1><script type="math/tex; mode=display">\begin{align}\end{align}</script><h2 id="1-RNN-Encoder-Decoder神经网络架构"><a href="#1-RNN-Encoder-Decoder神经网络架构" class="headerlink" title="1 RNN Encoder-Decoder神经网络架构"></a>1 RNN Encoder-Decoder神经网络架构</h2><p><img src="https://i.loli.net/2020/05/03/BpqV7omvnr1fLOd.png" srcset="/img/loading.gif"  align=center  width = "300" height = "300" /></p><p>RNN Encoder-Decoder神经网络架构使用循环神经网络学习将变长源序列$X$编码成定长向量表示$\mathbf{c}$，并将学习的定长向量表示$\mathbf{c}$解码成变长目标序列$Y$。模型的编码器和解码器被联合训练，以最大化给定源序列的目标序列的条件概率。</p><p>源文本序列：$X=\left(\mathbf{x}_{1}, \mathbf{x}_{2}, \dots, \mathbf{x}_{N}\right)$<br>其中，$\mathbf{x}_i=\left(l_1,l_2,\cdots,l_j,\cdots,l_K\right)$，其中$l_j=I\left(i=j\right),\quad\left(j=1,\cdots,K\right)$。</p><p>目标文本序列：$Y=\left(\mathbf{y}_{1}, \mathbf{y}_{2}, \dots, \mathbf{y}_{M}\right)$<br>其中，$\mathbf{y}_i=\left(l_1,l_2,\cdots,l_j,\cdots,l_K\right)$，其中$l_j=\left(i=j\right),\quad\left(j=1,\cdots,K\right)$</p><p>最大化条件似然函数</p><script type="math/tex; mode=display">\max_\theta \frac{1}{N}\sum_{n=1}^N \ln p_\theta\left(\mathbf{y}_n|\mathbf{x}_n\right)</script><p>其中，$\theta$是模型参数，$\left(\mathbf{y}_n,\mathbf{x}_n\right)$输入输出、输入序列对。</p><h2 id="2-编码器Encoder"><a href="#2-编码器Encoder" class="headerlink" title="2 编码器Encoder"></a>2 编码器Encoder</h2><p>源文本单词的词嵌入表示：$e\left(\mathbf{x}_i\right)\in\mathbb{R}^{500}$</p><p>编码器的隐藏状态由1000个隐藏单元组成。<br>编码器隐藏状态初始化，在$t=0$时刻第$j$个隐藏单元</p><script type="math/tex; mode=display">h_j^{\langle0\rangle}=0</script><p>在$t$时刻第$j$个隐藏单元<script type="math/tex">h_{j}^{\langle t\rangle}=z_{j} h_{j}^{\langle t-1\rangle}+\left(1-z_{j}\right) \tilde{h}_{j}^{\langle t\rangle}</script><br>其中，</p><script type="math/tex; mode=display">\begin{align}\tilde{h}_{j}^{\langle t \rangle}&=\tanh \left(\left[\mathbf{W} e\left(\mathbf{x}_{t}\right)\right]_{j}+\left[\mathbf{U}\left(\mathbf{r} \odot \mathbf{h}^{\langle t-1\rangle}\right)\right]_{j}\right)\\z_{j}&=\sigma\left(\left[\mathbf{W}_{z} e\left(\mathbf{x}_{t}\right)\right]_{j}+\left[\mathbf{U}_{z} \mathbf{h}^{\langle t-1\rangle}\right]_{j}\right) \\r_{j}&=\sigma\left(\left[\mathbf{W}_{r} e\left(\mathbf{x}_{t}\right)\right]_{j}+\left[\mathbf{U}_{r} \mathbf{h}^{\langle t-1\rangle}\right]_{j}\right)\end{align}</script><p>$\sigma\left(\cdot\right)$为sigmoid函数，$\odot$为向量元素乘法，$\mathbf{W},\mathbf{W}_z,\mathbf{W}_r\in\mathbb{R}^{1000\times 500}$和$\mathbf{U},\mathbf{U}_z,\mathbf{U}_r\in\mathbb{R}^{1000\times 1000}$为权值矩阵。为了使方程齐整，省略了偏置项。</p><p><img src="https://i.loli.net/2020/05/03/4nilNytzSkuX3jP.png" srcset="/img/loading.gif"  align=center tyle="zoom:10%" /></p><p>源文本最后第$N$时刻，编码器的隐藏状态计算完成，源文本的定长向量表示<script type="math/tex">\mathbf{c}=\tanh \left(\mathbf{V h}^{\langle N\rangle}\right)</script><br>其中，$\mathbf{V}\in\mathbb{R}^{1000\times 1000}$为权值矩阵。</p><h2 id="3-解码器Decoder"><a href="#3-解码器Decoder" class="headerlink" title="3 解码器Decoder"></a>3 解码器Decoder</h2><p>解码器隐藏状态初始化，在$t=0$时刻</p><script type="math/tex; mode=display">\mathbf{h}^{\prime\langle 0\rangle}=\tanh \left(\mathbf{V}^{\prime} \mathbf{c}\right)</script><p>其中，$\mathbf{V}\in\mathbb{R}^{1000\times 1000}$为权值矩阵。</p><p>在$t$时刻第$j$个隐藏单元</p><script type="math/tex; mode=display">h_{j}^{\prime\langle t\rangle}=z_{j}^{\prime} h_{j}^{\prime\langle t-1\rangle}+\left(1-z_{j}^{\prime}\right) \tilde{h^{\prime}}_{j}^{\langle t \rangle} )</script><p>其中，</p><script type="math/tex; mode=display">\begin{align}\tilde{h^{\prime}}_{j}^{\langle t\rangle}&=\tanh \left(\left[\mathbf{W}^{\prime} e\left(\mathbf{y}_{t-1}\right)\right]_{j}+r_{j}^{\prime}\left[\mathbf{U}^{\prime} \mathbf{h}_{\langle t-1\rangle}^{\prime}+\mathbf{C} \mathbf{c}\right]\right)  \\z_{j}^{\prime}&=\sigma\left(\left[\mathbf{W}_{z}^{\prime} e\left(\mathbf{y}_{t-1}\right)\right]_{j}+\left[\mathbf{U}_{z}^{\prime} \mathbf{h}^{\prime}_{\langle t-1\rangle}\right]_{j}+\left[\mathbf{C}_{z} \mathbf{c}\right]_{j}\right)  \\r_{j}^{\prime}&=\sigma\left(\left[\mathbf{W}_{r}^{\prime} e\left(\mathbf{y}_{t-1}\right)\right]_{j}+\left[\mathbf{U}_{r}^{\prime} \mathbf{h}^{\prime}_{\langle t-1\rangle}\right]_{j}+\left[\mathbf{C}_{r} \mathbf{c}\right]_{j}\right)\end{align}</script><p>其中，$\mathbf{W}^{\prime},\mathbf{W}_z^{\prime},\mathbf{W}_r^{\prime}\in\mathbb{R}^{1000\times 500}$和$\mathbf{U}^{\prime},\mathbf{U}_z^{\prime},\mathbf{U}_r^{\prime}\in\mathbb{R}^{1000\times 1000}$以及$\mathbf{C}^{\prime},\mathbf{C}_z^{\prime},\mathbf{C}_r^{\prime}\in\mathbb{R}^{1000\times 1000}$为权值矩阵。</p><p>目标文本单词的词嵌入表示：$e\left(\mathbf{y}_i\right)\in\mathbb{R}^{500}$，且在$t=0$时刻$e\left(\mathbf{y}_0\right)=\mathbf{0}$。</p><p>在每个时刻$t$，解码器计算生成第$j$个单词的概率</p><script type="math/tex; mode=display">p\left(y_{t, j}=1 | \mathbf{y}_{t-1}, \ldots, \mathbf{y}_{1}, X\right)=\frac{\exp \left(\mathbf{g}_{j} \mathbf{s}_{\langle t\rangle}\right)}{\sum_{j^{\prime}=1}^{K} \exp \left(\mathbf{g}_{j^{\prime}} \mathbf{s}_{\langle t\rangle}\right)}</script><p>其中，最大输出单元（maxout unit）</p><script type="math/tex; mode=display">s_{i}^{\langle t\rangle}=\max \left\{s_{2 i-1}^{\prime \langle t\rangle}, s_{2 i}^{\prime\langle t\rangle}\right\}</script><p>且</p><script type="math/tex; mode=display">\mathbf{s}^{\prime\langle t\rangle}=\mathbf{O}_{h} \mathbf{h}^{\prime\langle t\rangle}+\mathbf{O}_{y} \mathbf{y}_{t-1}+\mathbf{O}_{c} \mathbf{c}</script><p>$\mathbf{O}_h,\mathbf{O}_c\in\mathbb{R}^{500\times 1000}$和$\mathbf{O}_y\in\mathbb{R}^{500\times 500}$以及$\mathbf{G}=\left[\mathbf{g}_1,\cdots,\mathbf{g}_K\right]\in\mathbb{R}^{K\times 1000}$为权值矩阵。</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>encoder-decoder</tag>
      
      <tag>nlp</tag>
      
      <tag>seq2seq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer_Notes</title>
    <link href="/2020/05/03/Transformer-Notes/"/>
    <url>/2020/05/03/Transformer-Notes/</url>
    
    <content type="html"><![CDATA[<h1 id="Transformer特征提取器"><a href="#Transformer特征提取器" class="headerlink" title="Transformer特征提取器"></a>Transformer特征提取器</h1><script type="math/tex; mode=display">\begin{align}    \\     \end{align}    \\</script><p><img src="https://i.loli.net/2020/05/03/iQJMDVmbgIyx5F8.png" srcset="/img/loading.gif"  align=center  width = "300" height = "400" /></p><h2 id="1-输入序列、目标序列与输出序列"><a href="#1-输入序列、目标序列与输出序列" class="headerlink" title="1 输入序列、目标序列与输出序列"></a>1 输入序列、目标序列与输出序列</h2><p>输入序列$inputs=\left(i_1,i_2,\cdots,i_p,\cdots,i_N\right)$，其中$i_p\in\mathbb{N}$为输入符号表中的序号。<br>目标序列$targets=\left(t_1,t_2,\cdots,t_q,\cdots,t_M\right)$，其中$t_q\in\mathbb{N}$为目标符号表中的序号。        </p><script type="math/tex; mode=display">outputs\_probabilities=Transformer\left(inputs,targets\right)</script><p>其中，$outputs_probabilities=\left(o_1,o_2,\cdots,o_q,\cdots,o_M\right)$为预测序列，$o_q\in\mathbb{N*}$为目标符号表中的序号。</p><p>在自然语言处理任务中，当输入序列与目标序列中的元素较多，通常以句子为单位划分为若干个对应的“输入-目标”子序列进行学习。</p><h2 id="2-词嵌入与位置编码"><a href="#2-词嵌入与位置编码" class="headerlink" title="2 词嵌入与位置编码"></a>2 词嵌入与位置编码</h2><h3 id="输入序列词嵌入与位置编码"><a href="#输入序列词嵌入与位置编码" class="headerlink" title="输入序列词嵌入与位置编码"></a>输入序列词嵌入与位置编码</h3><p>输入序列词嵌入$Embedding\left(inputs\right)\in\mathbb{R}^{N\times d_{model}}$，其中，$N$为输入序列长度，$d_{model}$为词嵌入维度。</p><p>输入序列位置编码$Pos_Enc\left(inputs_position\right)\in\mathbb{R}^{N\times d_{model}}$，<br>其中，$inputs_position=\left(1,2,\cdots,p,\cdots,N\right)$为输入序列中输入符号对应的位置序号；  </p><script type="math/tex; mode=display">\begin{align}Pos\_Enc_{\left(pos,2i\right)}&=\sin\left(pos/10000^{2i/d_{model}}\right)  \\Pos\_Enc_{\left(pos,2i+1\right)}&=\cos\left(pos/10000^{2i/d_{model}}\right)\end{align}</script><p>其中，$pos\in inputs_position,i\in\left(0,1,\cdots,d_{model}/2\right)$。</p><h3 id="目标序列词嵌入与位置编码"><a href="#目标序列词嵌入与位置编码" class="headerlink" title="目标序列词嵌入与位置编码"></a>目标序列词嵌入与位置编码</h3><p>目标序列词嵌入$Embedding\left(targets\right)\in\mathbb{R}^{M\times d_{model}}$，其中$M$为目标序列长度，$d_{model}$为词嵌入维度。</p><p>目标序列位置编码$Pos_Enc\left(targets_position\right)\in\mathbb{R}^{M\times d_{model}}$，<br>其中，$targets_position=\left(1,2,\cdots,q,\cdots,M\right)$为目标序列的位置序号。</p><h2 id="3-编码器Encoder"><a href="#3-编码器Encoder" class="headerlink" title="3 编码器Encoder"></a>3 编码器Encoder</h2><h3 id="编码器结构"><a href="#编码器结构" class="headerlink" title="编码器结构"></a>编码器结构</h3><p>编码器结构：</p><script type="math/tex; mode=display">\begin{align}e_0&=Embedding\left(inputs\right)+Pos\_Enc\left(inputs\_position\right) \\e_l&=EncoderLayer\left(e_{l-1}\right),l\in\left[1,n\right] \\\end{align}</script><p>其中，$e_0\in\mathbb{R}^{N\times d_{model}}$为编码器输入，$EncoderLayer\left(\cdot\right)$为编码器层，$n$为层数，$e_l\in\mathbb{R}^{N\times d_{model}}$为第$l$层编码器层输出。</p><p>编码器层EncoderLayer：</p><script type="math/tex; mode=display">\begin{align}e_{mid}&=LayerNorm\left(e_{in}+MultiHeadAttention\left(e_{in}\right)\right) \\e_{out}&=LayerNorm\left(e_{mid}+FFN\left(e_{mid}\right)\right)\end{align}</script><p>其中，$e_{in}\in\mathbb{R}^{N\times d_{model}}$为编码器层输入，$e_{out}\in\mathbb{R}^{N\times d_{model}}$为编码器层输出，$MultiHeadAttention\left(\cdot\right)$为多头注意力机制，$FFN\left(\cdot\right)$为前馈神经网络，$LayerNorm\left(\cdot\right)$为层归一化。</p><h3 id="多头注意力机制与缩放点积"><a href="#多头注意力机制与缩放点积" class="headerlink" title="多头注意力机制与缩放点积"></a>多头注意力机制与缩放点积</h3><p><img src="https://i.loli.net/2020/05/03/3iRw2cN7gBqeWls.png" srcset="/img/loading.gif"  align=center tyle="zoom:50%" /></p><p>输入向量序列$e_{in}=\left(e_{in1},e_{in2},\cdots,e_{inN}\right)\in\mathbb{R}^{N\times d_{model}}$，分别得到查询向量序列$Q=e_{in}$，键向量序列$K=e_{in}$，值向量序列$V=e_{in}$。</p><p>多头注意力机制</p><script type="math/tex; mode=display">MultiHeadAttention\left(e_{in}\right)=MultiHead\left(Q,K,V\right)=Concat\left(head_1,\cdots,head_h\right)W^O</script><p>其中，多头输出$head_i=Attention\left(QW_i^Q,KW_i^K,VW_i^V\right)$，可学习的参数矩阵$W_i^Q\in\mathbb{R}^{d_{model}\times d_k},W_i^K\in\mathbb{R}^{d_{model}\times d_k},W_i^V\in\mathbb{R}^{d_{model}\times d_v},W^O\in\mathbb{R}^{hd_v\times d_{model}}$</p><p>使用缩放点积作为打分函数的自注意力机制</p><script type="math/tex; mode=display">Attention\left(QW_i^Q,KW_i^K,VW_i^K\right)=softmax\left(\frac{QW_i^Q\left(KW_i^K\right)^\top}{\sqrt{d_k}}\right)VW_i^V</script><h3 id="编码器pad掩码"><a href="#编码器pad掩码" class="headerlink" title="编码器pad掩码"></a>编码器pad掩码</h3><script type="math/tex; mode=display">enc\_pad\_mask_j=\left(e_{j1},e_{j2},\cdots,e_{jp},\cdots,e_{jN}\right)</script><p>其中，</p><script type="math/tex; mode=display">e_{jp}=\left\{\begin{array}{rcl}True,      &      & {i_p=0}\\False,     &      & {i_p \neq 0}\end{array} \right.   \quad j=1,2,\cdots,N</script><p>$enc_pad_mask\in\mathbb{R}^{N\times N}$，$i_p$为输入序列$inputs$对应位置序号。</p><h3 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><script type="math/tex; mode=display">\begin{align}FFN\left(e_{mid}\right)&=ReLU\left(e_{mid}W_1+b_1\right)W_2+b_2 \\&=\max\left(0,e_{mid}W_1+b_1\right)W_2+b_2\end{align}</script><p>其中，参数矩阵$W_1\in\mathbb{R}^{d_{model}\times d_{ff}},W_2\in\mathbb{R}^{d_{ff}\times d_{model}}$，偏置$b_1\in\mathbb{R}^{d_{ff}},b_2\in\mathbb{R}^{d_{model}}$。</p><h2 id="4-解码器Decoder"><a href="#4-解码器Decoder" class="headerlink" title="4 解码器Decoder"></a>4 解码器Decoder</h2><h3 id="解码器结构"><a href="#解码器结构" class="headerlink" title="解码器结构"></a>解码器结构</h3><script type="math/tex; mode=display">\begin{align}d_0&=Embedding\left(targets\right)+Pos\_Enc\left(targets\_position\right)  \\d_l&=DecoderLayer\left(d_{l-1}\right),l\in\left[1,n\right] \\outputs\_probabilities&=softmax\left(d_{n}W\right)\end{align}</script><p>其中，$d_0\in\mathbb{R}^{M\times d_{model}}$为解码器输入，$DecoderLayer\left(\cdot\right)$为解码器层，$n$为层数，$d_l\in\mathbb{R}^{M\times d_{model}}$为第$l$层解码器层输出，$W\in\mathbb{R}^{M\times tgt_vocab_size}$输入输出参数矩阵，$softmax\left(\cdot\right)$为softmax层。</p><p>解码器层DecoderLayer：</p><script type="math/tex; mode=display">\begin{align}d_{mid1}&=LayerNorm\left(d_{in}+MaskedMultiHeadAttention\left(d_{in}\right)\right) \\d_{mid2}&=LayerNorm\left(d_{mid1}+MultiHeadAttention\left(d_{mid1},e_{out}\right)\right) \\d_{out}&=LayerNorm\left(d_{mid2}+FFN\left(d_{mid2}\right)\right)\end{align}</script><p>其中，$d_{in}\in\mathbb{R}^{M\times d_{model}}$为解码器层输入，$d_{out}\in\mathbb{R}^{M\times d_{model}}$为解码器层输出，$MultiHeadAttention\left(\cdot\right)$为多头注意力机制，$FFN\left(\cdot\right)$为前馈神经网络，$LayerNorm\left(\cdot\right)$为层归一化。</p><h3 id="解码器pad掩码、解码器sequence掩码和编码器解码器pad掩码"><a href="#解码器pad掩码、解码器sequence掩码和编码器解码器pad掩码" class="headerlink" title="解码器pad掩码、解码器sequence掩码和编码器解码器pad掩码"></a>解码器pad掩码、解码器sequence掩码和编码器解码器pad掩码</h3><p>解码器pad掩码</p><script type="math/tex; mode=display">dec\_pad\_mask_j=\left(d_{j1},d_{j2},\cdots,d_{jq},\cdots,d_{jM}\right)</script><p>其中，</p><script type="math/tex; mode=display">d_{jq}=\left\{\begin{array}{rcl}True,      &      & {t_q=0}\\False,     &      & {t_q \neq 0}\end{array} \right.   \quad j=1,2,\cdots,M</script><p>$dec_pad_mask\in\mathbb{R}^{M\times M}$，$t_q$为目标序列$targets$对应位置序号。</p><p>解码器sequence掩码</p><script type="math/tex; mode=display">dec\_sequence\_mask_j=\left(s_{j1},s_{j2},\cdots,s_{jl},\cdots,s_{jM}\right)</script><p>其中，</p><script type="math/tex; mode=display">s_{jl}=\left\{\begin{array}{rcl}0,      &      & {j\geq l}\\1,     &      & {j < l}\end{array} \right.   \quad j=1,2,\cdots,M</script><p>$dec_sequence_mask\in\mathbb{R}^{M\times M}$，为非零元素为1的上三角矩阵。</p><p>解码器掩码</p><script type="math/tex; mode=display">dec\_mask=dec\_pad\_mask+dec\_sequence\_mask</script><p>编码器解码器pad掩码</p><script type="math/tex; mode=display">dec\_enc\_pad\_mask_j=\left(de_{j1},de_{j2},\cdots,de_{jp},\cdots,de_{jN}\right)</script><p>其中，</p><script type="math/tex; mode=display">de_{jp}=\left\{\begin{array}{rcl}True,      &      & {i_p=0}\\False,     &      & {i_p \neq 0}\end{array} \right.   \quad j=1,2,\cdots,M</script><p>$dec_enc_pad_mask\in\mathbb{R}^{M\times N}$，$i_p$为输入序列$inputs$对应位置序号。</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>encoder-decoder</tag>
      
      <tag>self attention</tag>
      
      <tag>multi-head attention</tag>
      
      <tag>nlp</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>XGBoost_Notes</title>
    <link href="/2020/05/02/XGBoost-Nots/"/>
    <url>/2020/05/02/XGBoost-Nots/</url>
    
    <content type="html"><![CDATA[<h1 id="XGBoost原理"><a href="#XGBoost原理" class="headerlink" title="XGBoost原理"></a>XGBoost原理</h1><script type="math/tex; mode=display">\begin{align}    \\ XGBoost&=eXtreme+GBDT  \\    &=eXtreme+(Gradient+BDT)    \\    &=eXtreme+Gradient+(Boosting+DecisionTree)   \\    \end{align}    \\</script><script type="math/tex; mode=display">Boosting \to BDT \to GBDT \to XGBoost</script><h2 id="1-提升方法（Boosting）"><a href="#1-提升方法（Boosting）" class="headerlink" title="1 提升方法（Boosting）"></a>1 提升方法（Boosting）</h2><p>提升方法使用加法模型和前向分步算法。</p><p>加法模型</p><script type="math/tex; mode=display">f\left(x\right)=\sum_{m=1}^M\beta_m b\left(x;\gamma_m\right)</script><p>其中，$b\left(x;\gamma_m\right)$为基函数，$\gamma_m$为基函数的参数，$\beta_m$为基函数的系数。</p><p>在给定训练数据$\{\left(x_i,y_i\right)\}_{i=1}^N$及损失函数$L\left(y,f\left(x\right)\right)$的条件下，学习加法模型$f\left(x\right)$成为经验风险极小化问题：</p><script type="math/tex; mode=display">\min_{\beta_m,\gamma_m}\sum_{i=1}^N L\left(y_i,\sum_{m=1}^M\beta_m b\left(x_i;\gamma_m\right)\right)</script><p>前向分步算法求解这一优化问题的思路：因为学习的是加法模型，可以从前向后，每一步只学习一个基函数及其系数，逐步逼近优化目标函数，则可以简化优化复杂度。具体地，每步只需优化如下损失函数：</p><script type="math/tex; mode=display">\min_{\beta,\gamma}\sum_{i=1}^N L\left(y_i,\beta b\left(x_i;\gamma\right)\right)</script><h3 id="算法1-1-前向分步算法"><a href="#算法1-1-前向分步算法" class="headerlink" title="算法1.1 前向分步算法"></a>算法1.1 前向分步算法</h3><p>输入：训练数据集$T=\{\left(x_1,y_1\right),\left(x_2,y_2\right),\dots,\left(x_N,y_N\right)\}$； 损失函数$L\left(y,f\left(x\right)\right)$；基函数集合$\{b\left(x;\gamma\right)\}$；   </p><p>输出：加法模型$f\left(x\right)$  </p><p>（1）初始化$f_0\left(x\right)=0$  </p><p>（2）对$m=1,2,\dots,M$  </p><p>（a）极小化损失函数</p><script type="math/tex; mode=display">\left(\beta_m,\gamma_m\right)=\mathop{\arg\min}_{\beta,\gamma} \sum_{i=1}^N L\left(y_i, f_{m-1}\left(x_i\right)+\beta b\left(x_i;\gamma\right)\right)</script><p>得到参数$\beta_m$，$\gamma_m$  </p><p>（b）更新</p><script type="math/tex; mode=display">f_m\left(x\right)=f_{m-1}\left(x\right)+\beta_m b\left(x;\gamma_m\right)</script><p>（3）得到加法模型  </p><script type="math/tex; mode=display">f\left(x\right)=f_M\left(x\right)=\sum_{m=1}^M\beta_m b\left(x;\gamma_m\right)</script><p>前向分步算法将同时求解从$m=1$到$M$所有参数$\beta_m,\gamma_m$的优化问题简化为逐次求解各个$\beta_m, \gamma_m$的优化问题。</p><h2 id="2-提升决策树-（BDT，Boosting-Decision-Tree）"><a href="#2-提升决策树-（BDT，Boosting-Decision-Tree）" class="headerlink" title="2 提升决策树 （BDT，Boosting Decision Tree）"></a>2 提升决策树 （BDT，Boosting Decision Tree）</h2><p>以决策树为基函数的提升方法为提升决策树。</p><p>提升决策树模型可以表示为决策树的加法模型：  </p><script type="math/tex; mode=display">f_M=\sum_{m=1}^M T\left(x;\Theta_m\right)</script><p>其中，$T\left(x;\Theta_m\right)$表示决策树；$\Theta_m$为决策树的参数；$M$为树的个数。</p><p>提升决策树采用前向分步算法。首先确定初始提升决策树$f_0\left(x\right)=0$，第$m$步的模型是</p><script type="math/tex; mode=display">f_m\left(x\right)=f_{m-1}\left(x\right)+T\left(x;\Theta_m\right)</script><p>其中，$f_{m-1}\left(x\right)$为当前模型，通过经验风险极小化确定下一棵决策树的参数$\Theta_m$，</p><script type="math/tex; mode=display">\hat{\Theta}_m=\mathop{\arg\min}_{\Theta_m}\sum_{i=1}^N L\left(y_i,f_{m-1}\left(x_i\right)+T\left(x_i;\Theta_m\right)\right)</script><p>已知训练数据集$T=\{\left(x_1,y_1\right),\left(x_2,y_2\right),\dots\left(x_N,y_N\right)\}$，$x_i\in\mathcal{X}\subseteq\mathbb{R}^n$，$\mathcal{X}$为输入空间，$y_i\in\mathcal{Y}\subseteq\mathbb{R}$，$\mathcal{Y}$为输出空间。如果将输入空间$\mathcal{X}$划分为$J$个互不相交的区域$R_1,R_2,\dots,R_J$，并且在每个区域上确定输出的常量$c_j$，那么决策树可表示为</p><script type="math/tex; mode=display">T\left(x;\Theta\right)=\sum_{j=1}^J c_j I\left(x\in R_j\right)</script><p>其中，参数$\Theta=\{\left(R_1,c_1\right),\left(R_2,c_2\right),\dots,\left(R_J,c_J\right)\}$表示决策树的区域划分和各区域上的常量值。$J$是决策树的复杂度即叶子结点个数。</p><p>提升决策树使用以下前向分步算法：</p><script type="math/tex; mode=display">\begin{align}f_0\left(x\right)&=0 \\f_m\left(x\right)&=f_{m-1}\left(x\right)+T\left(x;\Theta_m\right),\quad m=1,2,\dots,M        \\f_M\left(x\right)&=\sum_{m=1}^M T\left(x;\Theta_m\right)\end{align}</script><p>在前向分步算法的第$m$步，给定当前模型$f_{m-1}\left(x\right)$，需要求解</p><script type="math/tex; mode=display">\hat{\Theta}_m=\mathop{\arg\min}_{\Theta_m}\sum_{i=1}^N L\left(y_i,f_{m-1}\left(x_i\right)+T\left(x_i;\Theta_m\right)\right)</script><p>得到$\hat{\Theta}_m$，即第$m$棵树的参数。</p><p>当采用平方误差损失函数时，</p><script type="math/tex; mode=display">L\left(y,f\left(x\right)\right)=\left(y-f\left(x\right)\right)^2</script><p>其损失变为</p><script type="math/tex; mode=display">\begin{align}L\left(y,f_{m-1}\left(x\right)+T\left(x;\Theta_m\right)\right) &=\left[y-f_{m-1}\left(x\right)-T\left(x;\Theta_m\right)\right]^2 \\&=\left[r-T\left(x;\Theta_m\right)\right]^2\end{align}</script><p>其中，</p><script type="math/tex; mode=display">r=y-f_{m-1}\left(x\right)</script><p>是当前模型拟合数据的残差（residual）。对回归问题的提升决策树，只需要简单地拟合当前模型的残差。</p><h3 id="算法2-1-回归问题的提升决策树算法"><a href="#算法2-1-回归问题的提升决策树算法" class="headerlink" title="算法2.1 回归问题的提升决策树算法"></a>算法2.1 回归问题的提升决策树算法</h3><p>输入：训练数据集$T=\{\left(x_1,y_1\right),\left(x_2,y_2\right),\dots,\left(x_N,y_N\right)\}$；   </p><p>输出：提升决策树$f_M\left(x\right)$  </p><p>（1）初始化$f_0\left(x\right)=0$  </p><p>（2）对$m=1,2,\dots,M$  </p><p>（a）按照式（2.5）计算残差</p><script type="math/tex; mode=display">r_{mi}=y_i-f_{m-1}\left(x_i\right), \quad i=1,2,\dots,N</script><p>（b)拟合残差$r_{mi}$学习一个回归树，得到$T\left(x;\Theta_m\right)$  </p><p>（c）更新$f_m\left(x\right)=f_{m-1}\left(x\right)+T\left(x;\Theta_m\right) $  </p><p>（3）得到回归提升决策树 </p><script type="math/tex; mode=display">f_M\left(x\right)=\sum_{m=1}^M T\left(x;\Theta_m\right)</script><h2 id="3-梯度提升决策树-（GBDT，Gradient-Boosting-Decision-Tree）"><a href="#3-梯度提升决策树-（GBDT，Gradient-Boosting-Decision-Tree）" class="headerlink" title="3 梯度提升决策树 （GBDT，Gradient Boosting Decision Tree）"></a>3 梯度提升决策树 （GBDT，Gradient Boosting Decision Tree）</h2><p>梯度提升算法使用损失函数的负梯度在当前模型的值</p><script type="math/tex; mode=display">-\left[\frac{\partial L\left(y,f\left(x_i\right)\right)}{\partial f\left(x_i\right)}\right]_{f\left(x\right)=f_{m-1}\left(x\right)}</script><p>作为回归问题提升决策树算法中残差的近似值，拟合一个回归树。</p><h3 id="算法3-1-梯度提升算法"><a href="#算法3-1-梯度提升算法" class="headerlink" title="算法3.1 梯度提升算法"></a>算法3.1 梯度提升算法</h3><p>输入：训练数据集$T=\{\left(x_1,y_1\right),\left(x_2,y_2\right),\dots,\left(x_N,y_N\right)\}$； 损失函数$L\left(y,f\left(x\right)\right)$  </p><p>输出：梯度提升决策树$\hat{f}\left(x\right)$  </p><p>（1）初始化</p><script type="math/tex; mode=display">f_0\left(x\right)=\mathop{\arg\min}_c\sum_{i=1}^N L\left(y_i,c\right)</script><p>（2）对$m=1,2,\dots,M$  </p><p>（a）对$i=1,2,\dots,N$，计算</p><script type="math/tex; mode=display">r_{mi}=-\left[\frac{\partial L\left(y,f\left(x_i\right)\right)}{\partial f\left(x_i\right)}\right]_{f\left(x\right)=f_{m-1}\left(x\right)}</script><p> （b)对$r_{mi}$拟合一个回归树，得到第$m$棵树的叶结点区域$R_{mj},j=1,2,\dots,J$  </p><p>（c）对$j=1,2,\dots,J$，计算</p><script type="math/tex; mode=display">c_{mj}=\mathop{\arg\min}_c\sum_{x_i\in R_{mj}} L\left(y_i, f_{m-1}\left(x_i\right)+c\right)</script><p>（d）更新$f_m\left(x\right)=f_{m-1}\left(x\right)+\sum_{j=1}^J c_{mj} I\left(x\in R_{mj}\right)$  </p><p>（3）得到回归梯度提升决策树 </p><script type="math/tex; mode=display">\hat{f}\left(x\right)=f_M\left(x\right)=\sum_{m=1}^M \sum_{j=1}^J c_{mj} I\left(x\in R_{mj}\right)</script><h2 id="4-极致梯度提升决策树（XGBoost，eXtreme-Gradient-Boosting-Decision-Tree）"><a href="#4-极致梯度提升决策树（XGBoost，eXtreme-Gradient-Boosting-Decision-Tree）" class="headerlink" title="4 极致梯度提升决策树（XGBoost，eXtreme Gradient Boosting Decision Tree）"></a>4 极致梯度提升决策树（XGBoost，eXtreme Gradient Boosting Decision Tree）</h2><p>训练数据集$\mathcal{D}=\{\left(\mathbf{x}_i,y_i\right)\}$，其中$\mathbf{x}_i\in\mathbb{R}^m,y_i\in\mathbb{R},\left|\mathcal{D}\right|=n$。</p><p>决策树模型</p><script type="math/tex; mode=display">f\left(\mathbf{x}\right)=w_{q\left(\mathbf{x}\right)}</script><p>其中，$q:\mathbb{R}^m\to \{1,\dots,T\}$是有输入$\mathbf{x}$向叶子结点编号的映射，$w\in\mathbb{R}^T$是叶子结点向量，$T$为决策树叶子节点数。</p><p>提升决策树模型预测输出</p><script type="math/tex; mode=display">\hat{y}_i=\phi\left(\mathbf{x}_i\right)=\sum_{k=1}^K f_k\left(\mathbf{x}_i\right)</script><p>其中，$f_k\left(\mathbf{x}\right)$为第$k$棵决策树。</p><p>正则化目标函数</p><script type="math/tex; mode=display">\mathcal{L}\left(\phi\right)=\sum_i l\left(\hat{y}_i,y_i\right)+\sum_k \Omega\left(f_k\right)</script><p>其中，$\Omega\left(f\right)=\gamma T+\frac{1}{2}\lambda|w|^2=\gamma T+\frac{1}{2}\lambda\sum_{j=1}^T w_j^2$。</p><p>第$t$轮目标函数</p><script type="math/tex; mode=display">\mathcal{L}^{\left(t\right)}=\sum_{i=1}^n l\left(y_i,\hat{y}^{\left(t-1\right)}_i+f_t\left(\mathbf{x}_i\right)\right)+\Omega\left(f_t\right)</script><p>第$t$轮目标函数$\mathcal{L}^{\left(t\right)}$在$\hat{y}^{\left(t-1\right)}$处的二阶泰勒展开</p><script type="math/tex; mode=display">\begin{align}\mathcal{L}^{\left(t\right)}&\simeq\sum_{i=1}^n\left[l\left(y_i,\hat{y}^{\left(t-1\right)}\right)+\partial_{\hat{y}^{\left(t-1\right)}}l\left(y_i,\hat{y}^{\left(t-1\right)}\right) f_t\left(\mathbf{x}_i\right)+\frac{1}{2}\partial^2_{\hat{y}^{\left(t-1\right)}}l\left(y_i,\hat{y}^{\left(t-1\right)}\right) f^2_t\left(\mathbf{x}_i\right)\right]+\Omega\left(f_t\right)  \\&=\sum_{i=1}^n\left[l\left(y_i,\hat{y}^{\left(t-1\right)}\right)+g_i f_t\left(\mathbf{x}_i\right)+\frac{1}{2}h_i f^2_t\left(\mathbf{x}_i\right)\right]+\Omega\left(f_t\right)\end{align}</script><p>其中，$g_i=\partial_{\hat{y}^{\left(t-1\right)}}l\left(y_i,\hat{y}^{\left(t-1\right)}\right),h_i=\partial^2_{\hat{y}^{\left(t-1\right)}}l\left(y_i,\hat{y}^{\left(t-1\right)}\right)$。</p><p>第$t$轮目标函数$\mathcal{L}^{\left(t\right)}$的二阶泰勒展开移除关于$f_t\left(\mathbf{x}_i\right)$的常数项</p><script type="math/tex; mode=display">\begin{align}\tilde{\mathcal{L}}^{\left(t\right)}&=\sum_{i=1}^n\left[g_i f_t\left(\mathbf{x}_i\right)+\frac{1}{2}h_i f^2_t\left(\mathbf{x}_i\right)\right]+\Omega\left(f_t\right) \\&=\sum_{i=1}^n\left[g_i f_t\left(\mathbf{x}_i\right)+\frac{1}{2}h_i f^2_t\left(\mathbf{x}_i\right)\right]+\gamma T+\frac{1}{2}\lambda\sum_{j=1}^T w_j^2\end{align} \\</script><p>定义叶结点$j$上的样本的下标集合$I_j=\{i|q\left(\mathbf{x}_i\right)=j\}$，则目标函数可表示为按叶结点累加的形式</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}^{\left(t\right)}=\sum_{j=1}^T\left[\left(\sum_{i\in I_j}g_i\right)w_j+\frac{1}{2}\left(\sum_{i\in I_j}h_i+\lambda\right)w_j^2\right]+\gamma T</script><p>由于</p><script type="math/tex; mode=display">w_j^*=\mathop{\arg\min}_{w_j}\tilde{\mathcal{L}}^{\left(t\right)}</script><p>可令</p><script type="math/tex; mode=display">\frac{\partial\tilde{\mathcal{L}}^{\left(t\right)}}{\partial w_j}=0</script><p>得到每个叶结点$j$的最优分数为</p><script type="math/tex; mode=display">w_j^*=-\frac{\sum_{i\in I_j}g_i}{\sum_{i\in I_j} h_i+\lambda}</script><p>代入每个叶结点$j$的最优分数，得到最优化目标函数值</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}^{\left(t\right)}\left(q\right)=-\frac{1}{2}\sum_{j=1}^T \frac{\left(\sum_{i\in I_j} g_i\right)^2}{\sum_{i\in I_j} h_i+\lambda}+\gamma T</script><p>假设$I_L$和$I_R$分别为分裂后左右结点的实例集，令$I=I_L\cup I_R$，则分裂后损失减少量由下式得出</p><script type="math/tex; mode=display">\mathcal{L}_{split}=\frac{1}{2}\left[\frac{\left(\sum_{i\in I_L} g_i\right)^2}{\sum_{i\in I_L}h_i+\lambda}+\frac{\left(\sum_{i\in I_R} g_i\right)^2}{\sum_{i\in I_R}h_i+\lambda}-\frac{\left(\sum_{i\in I} g_i\right)^2}{\sum_{i\in I}h_i+\lambda}\right]-\gamma</script><p>用以评估待分裂结点。</p><h3 id="算法4-1-分裂查找的精确贪婪算法"><a href="#算法4-1-分裂查找的精确贪婪算法" class="headerlink" title="算法4.1 分裂查找的精确贪婪算法"></a>算法4.1 分裂查找的精确贪婪算法</h3><p>输入：当前结点实例集$I$;特征维度$d$  </p><p>输出：根据最大分值分裂  </p><p>（1）$gain\leftarrow 0$  </p><p>（2）$G\leftarrow\sum_{i\in I}g_i$，$H\leftarrow\sum_{i\in I}h_i$  </p><p>（3）for $k=1$ to $d$ do  </p><p>（3.1）$G_L \leftarrow 0$，$H_L \leftarrow 0$  </p><p>（3.2）for $j$ in sorted($I$, by $\mathbf{x}_{jk}$) do  </p><p>（3.2.1）$G_L \leftarrow G_L+g_j$，$H_L \leftarrow H_L+h_j$  </p><p>（3.2.2）$G_R \leftarrow G-G_L$，$H_R=H-H_L$  </p><p>（3.2.3）$score \leftarrow \max\left(score,\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{G^2}{H+\lambda}\right)$  </p><p>（3.3）end  </p><p>（4）end</p><h3 id="算法4-2-分裂查找的近似贪婪算法"><a href="#算法4-2-分裂查找的近似贪婪算法" class="headerlink" title="算法4.2 分裂查找的近似贪婪算法"></a>算法4.2 分裂查找的近似贪婪算法</h3><p>输入：当前结点实例集$I$;特征维度$d$  </p><p>输出：根据最大分值分裂  </p><p>（1）for $k=1$ to $d$ do  </p><p>（1.1）通过特征$k$的百分位数求候选分割点$S_k=\{s_{k1},s_{k2},\dots,s_{kl}\}$   </p><p>（1.2）可以在每颗树生成后（全局），可以在每次分裂后（局部）  </p><p>（2）end  </p><p>（3）for $k=1$ to $m$ do  </p><p>（3.1）$G_{kv}\gets =\sum_{j\in\{j|s_{k,v}\geq\mathbf{x}_{jk}&gt;s_{k,v-1}\}}g_j$  </p><p>（3.2）$H_{kv}\gets =\sum_{j\in\{j|s_{k,v}\geq\mathbf{x}_{jk}&gt;s_{k,v-1}\}}h_j$  </p><p>（4）end    </p><p>按照与前一节相同的步骤，在提议的分割中找到最大值。</p><p>候选分割点$S_k=\{s_{k1},s_{k2},\dots,s_{kl}\}$中，  </p><p>令</p><script type="math/tex; mode=display">s_{k1}=\min_i\mathbf{x}_{ik},\;s_{kl}=\max_i\mathbf{x}_{ik}</script><p>其余各分割点满足</p><script type="math/tex; mode=display">|r_k\left(s_{k,j}\right)-r_k\left(s_{k,j+1}\right)|<\epsilon</script><p>其中，函数$r_k:\mathbb{R}\to[0,+\infty)$</p><script type="math/tex; mode=display">r_k\left(z\right)=\frac{1}{\sum_{\left(x,h\right)\in\mathcal{D}_k}h}\sum_{\left(x,h\right)\in\mathcal{D}_k,x<z}h</script><p>其中$\mathcal{D}_k=\{\left(x_{1k},h_1\right),\left(x_{2k},h_2\right),\dots,\left(x_{nk},h_n\right)\} $</p><p>如果$h_i$作为数据点权重</p><script type="math/tex; mode=display">\sum_{i=1}^n\frac{1}{2}h_i\left(f_t\left(\mathbf{x}_i\right)-g_i/h_i\right)^2+\Omega\left(f_t\right)+constant</script><p>即是权重为$h_i$的$f_t\left(\mathbf{x}_i\right)$对$g_i/h_i$的加权平方损失。</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>decision tree</tag>
      
      <tag>boosting</tag>
      
      <tag>gbdt</tag>
      
      <tag>xgboost</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
